# ALMOEA:Learning to Accelerate Evolutionary Search for Large-Scale Multiobjective Optimization
Most existing evolutionary search strategies are not so efficient when directly handling the decision space of large-scale multiobjective optimization problems (LMOPs). To enhance the efficiency of tackling LMOPs, this paper proposes an accelerated evolutionary search (AES) strategy. Its main idea is to learn a gradient-descent-like direction vector for each solution via the specially trained feedforward neural network, which may be the learnt possibly fastest convergent direction to reproduce new solutions efficiently. To be specific, a multilayer perceptron with only one hidden layer is constructed, in which the number of neurons in the input and output layers is equal to the dimension of the decision space. Then, to get appropriate training data for the model, the current population is divided into two subsets based on the non-dominated sorting, and each poor solution in one subset with worse convergence will be paired to an elitist solution in another subset with the minimum angle to it, which is considered most likely to guide it with rapid convergence. Next, this multilayer perceptron is updated via backpropagation with gradient descent by using the above elaborately prepared dataset. At last, an accelerated large-scale multiobjective evolution-ary algorithm is designed by using AES as reproduction operator.
